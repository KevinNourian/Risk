{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.imputation import ArbitraryNumberImputer\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 300000\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('use_inf_as_na', True)\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Risk\\Data\\Data\\data 27.csv\",\n",
    "    index_col=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Sampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce Memory Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 19.35 MB\n",
      "Memory usage after optimization is: 6.69 MB\n",
      "Decreased by 65.4%\n"
     ]
    }
   ],
   "source": [
    "data = functions.reduce_memory_usage(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 101\n",
    "target = 'TARGET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = ArbitraryNumberImputer(arbitrary_number=-99999)\n",
    "ani.fit(data)\n",
    "data = ani.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type='gbdt', \n",
    "                           num_leaves=31, \n",
    "                           max_depth=-1, \n",
    "                           learning_rate=0.1, \n",
    "                           n_estimators=100,\n",
    "                           verbose=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Recursive Feature Elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_clf = LGBMClassifier(verbosity=-1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rfecv = RFECV(estimator=lgb_clf, step=1, cv=5, scoring='roc_auc')\n",
    "\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Optimal number of features (LightGBM): \", rfecv.n_features_)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (roc_auc)\")\n",
    "\n",
    "if hasattr(rfecv, 'grid_scores_'):\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "else:\n",
    "    plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Optuna**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-15 16:43:11,871] A new study created in memory with name: no-name-66d52709-46ac-4f45-a0fa-73c1a78265da\n",
      "[I 2024-10-15 16:43:15,855] Trial 0 finished with value: 0.718619020207611 and parameters: {'lambda_l1': 0.058569250566311695, 'lambda_l2': 0.021372900849422196, 'num_leaves': 151, 'feature_fraction': 0.70685573199695, 'bagging_fraction': 0.5132852451138763, 'bagging_freq': 5, 'min_child_samples': 33}. Best is trial 0 with value: 0.718619020207611.\n",
      "[I 2024-10-15 16:43:20,320] Trial 1 finished with value: 0.727229341915777 and parameters: {'lambda_l1': 0.0004901202960646275, 'lambda_l2': 0.025285362182444863, 'num_leaves': 292, 'feature_fraction': 0.5970276174404913, 'bagging_fraction': 0.5812791546512959, 'bagging_freq': 4, 'min_child_samples': 57}. Best is trial 1 with value: 0.727229341915777.\n",
      "[I 2024-10-15 16:43:29,324] Trial 2 finished with value: 0.7178546001657912 and parameters: {'lambda_l1': 1.5867137160199242e-08, 'lambda_l2': 2.068378927361673e-05, 'num_leaves': 186, 'feature_fraction': 0.6847736106412785, 'bagging_fraction': 0.5450332404957878, 'bagging_freq': 2, 'min_child_samples': 16}. Best is trial 1 with value: 0.727229341915777.\n",
      "[I 2024-10-15 16:43:39,153] Trial 3 finished with value: 0.7349283516840528 and parameters: {'lambda_l1': 0.8079938448878377, 'lambda_l2': 5.723551996901553e-05, 'num_leaves': 120, 'feature_fraction': 0.8495442437968128, 'bagging_fraction': 0.6626651635263416, 'bagging_freq': 2, 'min_child_samples': 81}. Best is trial 3 with value: 0.7349283516840528.\n",
      "[I 2024-10-15 16:43:44,481] Trial 4 finished with value: 0.7309995436340643 and parameters: {'lambda_l1': 0.011525826523173346, 'lambda_l2': 0.0001392981403680789, 'num_leaves': 229, 'feature_fraction': 0.9733506331444344, 'bagging_fraction': 0.7745277529100469, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 3 with value: 0.7349283516840528.\n",
      "[I 2024-10-15 16:43:57,864] Trial 5 finished with value: 0.7318929644389554 and parameters: {'lambda_l1': 0.027936274942674002, 'lambda_l2': 2.4625130182383226e-06, 'num_leaves': 106, 'feature_fraction': 0.8053576100317854, 'bagging_fraction': 0.9806223820950489, 'bagging_freq': 6, 'min_child_samples': 51}. Best is trial 3 with value: 0.7349283516840528.\n",
      "[I 2024-10-15 16:44:11,382] Trial 6 finished with value: 0.7364052222803131 and parameters: {'lambda_l1': 1.0864549753635062e-05, 'lambda_l2': 0.6403558651215523, 'num_leaves': 54, 'feature_fraction': 0.8573218504601561, 'bagging_fraction': 0.488016343609441, 'bagging_freq': 6, 'min_child_samples': 85}. Best is trial 6 with value: 0.7364052222803131.\n",
      "[I 2024-10-15 16:44:15,490] Trial 7 finished with value: 0.7179613080066806 and parameters: {'lambda_l1': 1.2179487128178176e-07, 'lambda_l2': 3.625457757416149e-05, 'num_leaves': 112, 'feature_fraction': 0.9139791787545669, 'bagging_fraction': 0.48197476236298487, 'bagging_freq': 3, 'min_child_samples': 13}. Best is trial 6 with value: 0.7364052222803131.\n",
      "[I 2024-10-15 16:44:19,103] Trial 8 finished with value: 0.7413994048215757 and parameters: {'lambda_l1': 6.882925520391644e-08, 'lambda_l2': 0.0715625443249791, 'num_leaves': 60, 'feature_fraction': 0.6242172466372449, 'bagging_fraction': 0.9388421997233861, 'bagging_freq': 7, 'min_child_samples': 52}. Best is trial 8 with value: 0.7413994048215757.\n",
      "[I 2024-10-15 16:44:35,135] Trial 9 finished with value: 0.7371680094010814 and parameters: {'lambda_l1': 0.8032565413206437, 'lambda_l2': 3.481008550440695, 'num_leaves': 281, 'feature_fraction': 0.8028135788416382, 'bagging_fraction': 0.9105367949519806, 'bagging_freq': 1, 'min_child_samples': 93}. Best is trial 8 with value: 0.7413994048215757.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.7413994048215757\n",
      "  Params: \n",
      "    lambda_l1: 6.882925520391644e-08\n",
      "    lambda_l2: 0.0715625443249791\n",
      "    num_leaves: 60\n",
      "    feature_fraction: 0.6242172466372449\n",
      "    bagging_fraction: 0.9388421997233861\n",
      "    bagging_freq: 7\n",
      "    min_child_samples: 52\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_test, label=y_test, reference=train_data)  # Validation data for early stopping\n",
    "\n",
    "   \n",
    "    gbm = lgb.train(\n",
    "        param,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],  \n",
    "        num_boost_round=100,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "    )\n",
    "\n",
    "   \n",
    "    y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
