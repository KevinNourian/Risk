{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 300000\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Risk\\Data\\application_train.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "# previous_apps = pd.read_csv(\n",
    "#     r\"C:\\Users\\Dell\\Documents\\AI\\Risk\\Data\\previous_application.csv\",\n",
    "#     index_col=False\n",
    "# )\n",
    "\n",
    "# app_test = pd.read_csv(\n",
    "#     r\"C:\\Users\\Dell\\Documents\\AI\\Risk\\Data\\application_test.csv\",\n",
    "#     index_col=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 101\n",
    "target = 'TARGET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Remove Empty Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_columns = functions.check_columns_with_one_uniquevalue(app_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# app_train = app_train.drop(list_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some of the variables in the dataset contain NaN. Check and remove those before using this transformer.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeature_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mselection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropConstantFeatures\n\u001b[0;32m      3\u001b[0m dcf \u001b[38;5;241m=\u001b[39m DropConstantFeatures(tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.75\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Risk\\riskvenv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Risk\\riskvenv\\lib\\site-packages\\sklearn\\base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1084\u001b[0m             (\n\u001b[0;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1094\u001b[0m         )\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Risk\\riskvenv\\lib\\site-packages\\feature_engine\\selection\\drop_constant_features.py:184\u001b[0m, in \u001b[0;36mDropConstantFeatures.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables_ \u001b[38;5;241m=\u001b[39m _select_all_variables(\n\u001b[0;32m    179\u001b[0m     X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfirm_variables\n\u001b[0;32m    180\u001b[0m )\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# check if dataset contains na\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m     \u001b[43m_check_contains_na\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariables_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing_values \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    187\u001b[0m     X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables_] \u001b[38;5;241m=\u001b[39m X[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables_]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\Documents\\AI\\Risk\\riskvenv\\lib\\site-packages\\feature_engine\\dataframe_checks.py:268\u001b[0m, in \u001b[0;36m_check_contains_na\u001b[1;34m(X, variables)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03mChecks if DataFrame contains null values in the selected columns.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    If the variable(s) contain null values.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X[variables]\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 268\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    269\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome of the variables in the dataset contain NaN. Check and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mremove those before using this transformer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    271\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Some of the variables in the dataset contain NaN. Check and remove those before using this transformer."
     ]
    }
   ],
   "source": [
    "from feature_engine.selection import DropConstantFeatures\n",
    "\n",
    "dcf = DropConstantFeatures(tol = 0.75)\n",
    "dcf.fit_transform(app_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 69)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop Collinear Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcf = DropCorrelatedFeatures(threshold=0.7)\n",
    "previous_apps = dcf.fit_transform(previous_apps)\n",
    "app_train = dcf.fit_transform(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce Memory Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 407.77 MB\n",
      "Memory usage after optimization is: 277.15 MB\n",
      "Decreased by 32.0%\n",
      "Memory usage of dataframe is 161.88 MB\n",
      "Memory usage after optimization is: 64.52 MB\n",
      "Decreased by 60.1%\n"
     ]
    }
   ],
   "source": [
    "previous_apps = functions.reduce_memory_usage(previous_apps)\n",
    "\n",
    "app_train = functions.reduce_memory_usage(app_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.MissingValues(previous_apps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop Features (More than 50% Missing)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['RATE_INTEREST_PRIMARY', 'RATE_INTEREST_PRIVILEGED', 'RATE_DOWN_PAYMENT', 'AMT_DOWN_PAYMENT']\n",
    "previous_apps = previous_apps.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Impute Missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_value = -99999\n",
    "\n",
    "for col in previous_apps.select_dtypes(include=['float16', 'float32', 'float64']).columns:\n",
    "    previous_apps[col].fillna(num_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_value = -99999\n",
    "\n",
    "for col in app_train.select_dtypes(include=['float16', 'float32', 'float64']).columns:\n",
    "    app_train[col].fillna(num_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_value = 'UNKNOWN'\n",
    "\n",
    "for col in previous_apps.select_dtypes(include=['object']).columns:\n",
    "    previous_apps[col].fillna(cat_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_value = 'UNKNOWN'\n",
    "\n",
    "for col in app_train.select_dtypes(include=['object']).columns:\n",
    "    app_train[col].fillna(cat_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aggregation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NUM_PREVIOUS_APPLICATIONS</th>\n",
       "      <th>AVG_ANNUITY_AMOUNT</th>\n",
       "      <th>AVG_DAYS_DECISION</th>\n",
       "      <th>MAX_DAYS_DECISION</th>\n",
       "      <th>MIN_DAYS_DECISION</th>\n",
       "      <th>SUM_CNT_PAYMENT</th>\n",
       "      <th>RANGE_DAYS_FIRST_DUE</th>\n",
       "      <th>RANGE_DAYS_LAST_DUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "      <td>3951.000000</td>\n",
       "      <td>-1740.0</td>\n",
       "      <td>-1740</td>\n",
       "      <td>-1740</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>9251.775391</td>\n",
       "      <td>-606.0</td>\n",
       "      <td>-606</td>\n",
       "      <td>-606</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>3</td>\n",
       "      <td>56553.988281</td>\n",
       "      <td>-1305.0</td>\n",
       "      <td>-746</td>\n",
       "      <td>-2341</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "      <td>5357.250000</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>-815</td>\n",
       "      <td>-815</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>2</td>\n",
       "      <td>-47592.898438</td>\n",
       "      <td>-536.0</td>\n",
       "      <td>-315</td>\n",
       "      <td>-757</td>\n",
       "      <td>-inf</td>\n",
       "      <td>99293.0</td>\n",
       "      <td>99533.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  NUM_PREVIOUS_APPLICATIONS  AVG_ANNUITY_AMOUNT  \\\n",
       "0      100001                          1         3951.000000   \n",
       "1      100002                          1         9251.775391   \n",
       "2      100003                          3        56553.988281   \n",
       "3      100004                          1         5357.250000   \n",
       "4      100005                          2       -47592.898438   \n",
       "\n",
       "   AVG_DAYS_DECISION  MAX_DAYS_DECISION  MIN_DAYS_DECISION  SUM_CNT_PAYMENT  \\\n",
       "0            -1740.0              -1740              -1740              8.0   \n",
       "1             -606.0               -606               -606             24.0   \n",
       "2            -1305.0               -746              -2341             30.0   \n",
       "3             -815.0               -815               -815              4.0   \n",
       "4             -536.0               -315               -757             -inf   \n",
       "\n",
       "   RANGE_DAYS_FIRST_DUE  RANGE_DAYS_LAST_DUE  \n",
       "0                   0.0                  0.0  \n",
       "1                   0.0                  0.0  \n",
       "2                1594.0               1444.0  \n",
       "3                   0.0                  0.0  \n",
       "4               99293.0              99533.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_previous_app = previous_apps.groupby('SK_ID_CURR').agg({\n",
    "    'SK_ID_PREV': 'count',  \n",
    "    'AMT_ANNUITY': 'mean',    \n",
    "    'DAYS_DECISION': ['mean', 'max', 'min'],  \n",
    "    'CNT_PAYMENT': ['sum'],\n",
    "    'DAYS_FIRST_DUE': lambda x: x.max() - x.min(),\n",
    "    'DAYS_LAST_DUE': lambda x: x.max() - x.min()\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten multi-level columns generated by the aggregations\n",
    "aggregated_previous_app.columns = ['_'.join(col).strip() if type(col) is tuple else col for col in aggregated_previous_app.columns]\n",
    "\n",
    "aggregated_previous_app = aggregated_previous_app.rename(columns={\n",
    "    'SK_ID_CURR_': 'SK_ID_CURR', \n",
    "    'SK_ID_PREV_count': 'NUM_PREVIOUS_APPLICATIONS',\n",
    "    'AMT_ANNUITY_mean': 'AVG_ANNUITY_AMOUNT',\n",
    "    'DAYS_DECISION_mean': 'AVG_DAYS_DECISION',\n",
    "    'DAYS_DECISION_max': 'MAX_DAYS_DECISION',\n",
    "    'DAYS_DECISION_min': 'MIN_DAYS_DECISION',\n",
    "    'CNT_PAYMENT_sum': 'SUM_CNT_PAYMENT',\n",
    "    'DAYS_FIRST_DUE_<lambda>': 'RANGE_DAYS_FIRST_DUE',\n",
    "    'DAYS_LAST_DUE_<lambda>': 'RANGE_DAYS_LAST_DUE',\n",
    "})\n",
    "\n",
    "aggregated_previous_app.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Merge Application Train and Previous Application Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = app_train.merge(aggregated_previous_app, on='SK_ID_CURR', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FLAG_DOCUMENT_5', \n",
    "                    'FLAG_DOCUMENT_17',\n",
    "                    'FLAG_DOCUMENT_15',\n",
    "                    'FLAG_DOCUMENT_12',\n",
    "                    'FLAG_DOCUMENT_14',\n",
    "                    'FLAG_DOCUMENT_2',\n",
    "                    'FLAG_DOCUMENT_10',\n",
    "                    'FLAG_DOCUMENT_20',\n",
    "                    'FLAG_DOCUMENT_19',\n",
    "                   'LIVE_CITY_NOT_WORK_CITY', \n",
    "                   'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                   'FLAG_DOCUMENT_8',\n",
    "                   'FLAG_MOBIL',\n",
    "                   'FLAG_CONT_MOBILE',\n",
    "                   'REG_REGION_NOT_LIVE_REGION',\n",
    "                   'FLAG_DOCUMENT_9',\n",
    "                   'FLAG_DOCUMENT_4',\n",
    "                   'FLAG_DOCUMENT_7',\n",
    "                   'FLAG_EMP_PHONE',\n",
    "                   'REG_REGION_NOT_WORK_REGION',\n",
    "                   'HOUSETYPE_MODE',\n",
    "                   'FLOORSMIN_MODE',\n",
    "                    'FLOORSMIN_MEDI',\n",
    "                    'ENTRANCES_MEDI',\n",
    "                    'FLOORSMAX_MODE'\n",
    "                   ] \n",
    "data = data.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WoE Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe = WoEEncoder(fill_value=0.0001)\n",
    "woe.fit(data, data[target])\n",
    "data = woe.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('TARGET', axis=1)\n",
    "y = data['TARGET']\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type='gbdt', \n",
    "                           num_leaves=31, \n",
    "                           max_depth=-1, \n",
    "                           learning_rate=0.1, \n",
    "                           n_estimators=100,\n",
    "                           verbose=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Drop Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FLAG_DOCUMENT_5', \n",
    "                    'FLAG_DOCUMENT_17',\n",
    "                    'FLAG_DOCUMENT_15',\n",
    "                    'FLAG_DOCUMENT_12',\n",
    "                    'FLAG_DOCUMENT_14',\n",
    "                    'FLAG_DOCUMENT_2',\n",
    "                    'FLAG_DOCUMENT_10',\n",
    "                    'FLAG_DOCUMENT_20',\n",
    "                    'FLAG_DOCUMENT_19',\n",
    "                   'LIVE_CITY_NOT_WORK_CITY', \n",
    "                   'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    "                   'FLAG_DOCUMENT_8',\n",
    "                   'FLAG_MOBIL',\n",
    "                   'FLAG_CONT_MOBILE',\n",
    "                   'REG_REGION_NOT_LIVE_REGION',\n",
    "                   'FLAG_DOCUMENT_9',\n",
    "                   'FLAG_DOCUMENT_4',\n",
    "                   'FLAG_DOCUMENT_7',\n",
    "                   'FLAG_EMP_PHONE',\n",
    "                   'REG_REGION_NOT_WORK_REGION',\n",
    "                   'HOUSETYPE_MODE',\n",
    "                   'FLOORSMIN_MODE',\n",
    "                    'FLOORSMIN_MEDI',\n",
    "                    'ENTRANCES_MEDI',\n",
    "                    'FLOORSMAX_MODE'\n",
    "                   ] \n",
    "data = data.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Recurssive Feature Elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x2\n",
       "0   2\n",
       "1   4\n",
       "2   3\n",
       "3   1\n",
       "4   2\n",
       "5   2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from feature_engine.selection import RecursiveFeatureElimination\n",
    "X = pd.DataFrame(dict(x1 = [1000,2000,1000,1000,2000,3000],\n",
    "                    x2 = [2,4,3,1,2,2],\n",
    "                    x3 = [1,1,1,0,0,0],\n",
    "                    x4 = [1,2,1,1,0,1],\n",
    "                    x5 = [1,1,1,1,1,1]))\n",
    "y = pd.Series([1,0,0,1,1,0])\n",
    "rfe = RecursiveFeatureElimination(RandomForestClassifier(random_state=2), cv=2)\n",
    "rfe.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 30\n",
      "Selected number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.selection import RecursiveFeatureElimination\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Load a sample dataset (Breast cancer dataset)\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model for feature selection (Logistic Regression)\n",
    "model = LogisticRegression(max_iter=2000, solver='lbfgs', random_state=42)\n",
    "\n",
    "# Define a custom scorer using AUC with response_method='predict_proba' (for ROC AUC scoring)\n",
    "auc_scorer = make_scorer(roc_auc_score, response_method='predict_proba')\n",
    "\n",
    "# Initialize Recursive Feature Elimination with AUC as scoring\n",
    "rfe = RecursiveFeatureElimination(\n",
    "    estimator=model,\n",
    "    variables=None,  # If None, RFE will evaluate all numerical features\n",
    "    scoring=auc_scorer,  # Use AUC for scoring\n",
    "    threshold=0.01,  # Feature importance threshold to drop variables\n",
    "    cv=3  # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "# Fit the RFE\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the datasets to retain only selected features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Original number of features:\", X_train.shape[1])\n",
    "print(\"Selected number of features:\", X_train_selected.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine.selection import RecursiveFeatureElimination\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# # Load a sample dataset (Breast cancer dataset)\n",
    "# data = load_breast_cancer()\n",
    "# X, y = data.data, data.target\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# # Scale the data using StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the model for feature selection (Logistic Regression)\n",
    "model = lgb.LGBMClassifier(boosting_type='gbdt', \n",
    "                           num_leaves=31, \n",
    "                           max_depth=-1, \n",
    "                           learning_rate=0.1, \n",
    "                           n_estimators=100,\n",
    "                           verbose=-1)\n",
    "\n",
    "# Define a custom scorer using AUC with response_method='predict_proba' (for ROC AUC scoring)\n",
    "auc_scorer = make_scorer(roc_auc_score, response_method='predict_proba')\n",
    "\n",
    "# Initialize Recursive Feature Elimination with AUC as scoring\n",
    "rfe = RecursiveFeatureElimination(\n",
    "    estimator=model,\n",
    "    variables=None,  # If None, RFE will evaluate all numerical features\n",
    "    scoring=auc_scorer,  # Use AUC for scoring\n",
    "    threshold=0.01,  # Feature importance threshold to drop variables\n",
    "    cv=3,  # Number of cross-validation folds\n",
    "    n_features_to_select=3\n",
    ")\n",
    "\n",
    "# Fit the RFE\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the datasets to retain only selected features\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Original number of features:\", X_train.shape[1])\n",
    "print(\"Selected number of features:\", X_train_selected.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Sample dataset\n",
    "# np.random.seed(42)\n",
    "# X = pd.DataFrame({\n",
    "#     'feature_1': np.random.rand(100),\n",
    "#     'feature_2': np.random.rand(100),\n",
    "#     'feature_3': np.random.rand(100),\n",
    "#     'feature_4': np.random.rand(100),\n",
    "#     'feature_5': np.random.rand(100),\n",
    "# })\n",
    "\n",
    "# # Create a target variable\n",
    "# y = np.random.randint(2, size=100)\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RFE with a RandomForest model\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=3)\n",
    "\n",
    "# Fit RFE\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Transform the dataset\n",
    "X_rfe = rfe.transform(X_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "print(\"Selected Features:\", selected_features.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
