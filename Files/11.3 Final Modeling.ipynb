{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> **Home Credit Default Risk Assessment**\n",
    "# <center> **Final Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the project, I compare: Logistic Regression, Random Forest, XGB and LightGBM and measure their performance using ROC-AUC socres. I use Optuna for hyperparameter tuning of the best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Documents\\AI\\Risk\\riskvenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from feature_engine.imputation import ArbitraryNumberImputer\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import optuna\n",
    "import pickle\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 300000\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('use_inf_as_na', True)\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Risk\\Data\\Data\\data 27.csv\",\n",
    "    index_col=False\n",
    ")\n",
    "\n",
    "data = data.drop('SK_ID_CURR', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 101\n",
    "target = 'TARGET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputation of missing values in the numeric and categorical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = ArbitraryNumberImputer(arbitrary_number=-99999)\n",
    "ani.fit(data)\n",
    "data = ani.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = CategoricalImputer(imputation_method='missing', fill_value='UNKNOWN')\n",
    "ci.fit(data)\n",
    "data = ci.transform(data)\n",
    "\n",
    "clean_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_data.drop(target, axis=1)\n",
    "y = clean_data[target]\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use Logistic Regression, Random Forest, XGB Classifier and LGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: ROC AUC = 0.63 (3.84 minutes)\n",
      "Random Forest: ROC AUC = 0.73 (2.33 minutes)\n",
      "XGBClassifier: ROC AUC = 0.72 (0.21 minutes)\n",
      "LightGBM: ROC AUC = 0.74 (0.18 minutes)\n"
     ]
    }
   ],
   "source": [
    "columns_to_scale = ['ANNUITY_TO_CREDIT_RATIO', \n",
    "                    'EXT_SOURCE_3',\n",
    "                    'EXT_SOURCE_2',\n",
    "                    'EXT_SOURCE_1',\n",
    "                    'EXT_SOURCE_MEAN',\n",
    "                    'ANNUAL_PAYMENT_TO_CREDIT_RATIO',\n",
    "                    'AGE',\n",
    "                    'YEARS_ID_PUBLISH',\n",
    "                    'AMT_ANNUITY',\n",
    "                    'AMT_GOODS_PRICE',\n",
    "                    'ANNUITY_TO_INCOME_RATIO',\n",
    "                    'YEARS_REGISTRATION',\n",
    "                    'YEARS_LAST_PHONE_CHANGE',\n",
    "                    'YEARS_EMPLOYED_AGE_PRODUCT',\n",
    "                    'INCOME_TO_AGE_RATIO',\n",
    "                    'REGION_POPULATION_RELATIVE',\n",
    "                    'AVG_MAX_DPD',\n",
    "                    'TOTAL_DEBIT',\n",
    "                    'TOTAL_CREDIT_AMT',\n",
    "                    'DEBT_CREDIT_RATIO',\n",
    "                    'AVG_ANNUITY_AMOUNT',\n",
    "                    'AVG_DAYS_DECISION',\n",
    "                    'RANGE_DAYS_FIRST_DUE',\n",
    "                    'RANGE_DAYS_LAST_DUE',\n",
    "                    'SUM_AMT_INSTALMENT',\n",
    "                    'AVG_AMT_INSTALMENT',\n",
    "                    'SUM_AMT_PAYMENT',\n",
    "                    'AVG_AMT_PAYMENT',\n",
    "                    'MAX_AMT_PAYMENT',\n",
    "                    'MIN_AMT_PAYMENT',\n",
    "                    'SUM_AMT_PAYMENT/SUM_AMT_INSTALMENT',\n",
    "                    'MEAN_AMT_PAYMENT-MEAN_AMT_INSTALMENT'\n",
    "                    ]\n",
    "\n",
    "columns_to_encode =  ['ORGANIZATION_TYPE']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), columns_to_scale),\n",
    "        ('encoder', WoEEncoder(fill_value=.000001), columns_to_encode)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "\n",
    "lg_model = LogisticRegression(class_weight='balanced', random_state=random_state, max_iter=5000)\n",
    "lg_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lg', lg_model)\n",
    "])\n",
    "\n",
    "\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=random_state)\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('random_forest', rf_model)\n",
    "])\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(class_weight='balanced', random_state=random_state, verbosity=0)\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('xgb', xgb_model)\n",
    "])\n",
    "\n",
    "\n",
    "lgbm_model = LGBMClassifier(class_weight='balanced', random_state=random_state, verbose=0)\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm_model)\n",
    "])\n",
    "\n",
    "\n",
    "pipelines = {\n",
    "    \"Logistic Regression\": lg_pipeline,\n",
    "    \"Random Forest\": rf_pipeline,\n",
    "    \"XGBClassifier\": xgb_pipeline,\n",
    "    \"LightGBM\": lgbm_pipeline\n",
    " \n",
    "}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    start_time = time.time()\n",
    "\n",
    "    y_pred_proba = cross_val_predict(pipeline, X, y, cv=10, method='predict_proba')[:, 1]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y, y_pred_proba)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    elapsed_time = (end_time - start_time) / 60\n",
    "\n",
    "    print(f\"{name}: ROC AUC = {roc_auc:.2f} ({elapsed_time:.2f} minutes)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Optuna**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I use Optuna for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe = WoEEncoder(fill_value=0.0001)\n",
    "woe.fit(clean_data, clean_data[target])\n",
    "encoded_data = woe.transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =encoded_data.drop(target, axis=1)\n",
    "y = encoded_data[target]\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-21 18:52:34,728] A new study created in memory with name: no-name-6e405dd0-ebfa-4fbf-8f1a-861196090f8a\n",
      "[I 2024-10-21 18:52:45,433] Trial 0 finished with value: 0.7639339114362902 and parameters: {'boosting_type': 'goss', 'num_leaves': 905, 'max_depth': 36, 'n_estimators': 176, 'learning_rate': 0.08246439374394156, 'min_child_samples': 194, 'min_gain_to_split': 0.035782813568435996}. Best is trial 0 with value: 0.7639339114362902.\n",
      "[I 2024-10-21 18:52:50,197] Trial 1 finished with value: 0.7623579710658642 and parameters: {'boosting_type': 'dart', 'num_leaves': 832, 'max_depth': 24, 'n_estimators': 63, 'learning_rate': 0.1348266610981248, 'min_child_samples': 423, 'min_gain_to_split': 0.9273121311831558}. Best is trial 0 with value: 0.7639339114362902.\n",
      "[I 2024-10-21 18:52:54,981] Trial 2 finished with value: 0.764506874417849 and parameters: {'boosting_type': 'goss', 'num_leaves': 158, 'max_depth': 57, 'n_estimators': 242, 'learning_rate': 0.1315159470580571, 'min_child_samples': 154, 'min_gain_to_split': 0.26960983782885733}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 18:52:57,719] Trial 3 finished with value: 0.7237309865297474 and parameters: {'boosting_type': 'goss', 'num_leaves': 628, 'max_depth': 17, 'n_estimators': 332, 'learning_rate': 0.7498838984600917, 'min_child_samples': 249, 'min_gain_to_split': 0.010318035223992472}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 18:53:34,090] Trial 4 finished with value: 0.7575928974353541 and parameters: {'boosting_type': 'dart', 'num_leaves': 756, 'max_depth': 22, 'n_estimators': 105, 'learning_rate': 0.20510461315853065, 'min_child_samples': 374, 'min_gain_to_split': 0.004714892086753698}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 18:54:08,038] Trial 5 finished with value: 0.760016676513533 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 866, 'max_depth': 29, 'n_estimators': 160, 'learning_rate': 0.011278991983646127, 'min_child_samples': 375, 'min_gain_to_split': 0.004149438766445979}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 18:56:04,612] Trial 6 finished with value: 0.7350284784102276 and parameters: {'boosting_type': 'dart', 'num_leaves': 736, 'max_depth': 27, 'n_estimators': 230, 'learning_rate': 0.2536854772144358, 'min_child_samples': 271, 'min_gain_to_split': 0.0026209143055915055}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 19:00:26,399] Trial 7 finished with value: 0.7171892523540732 and parameters: {'boosting_type': 'dart', 'num_leaves': 608, 'max_depth': 64, 'n_estimators': 380, 'learning_rate': 0.32509676563669404, 'min_child_samples': 317, 'min_gain_to_split': 0.00036838079702849574}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 19:00:34,337] Trial 8 finished with value: 0.7423183356603296 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 75, 'max_depth': 18, 'n_estimators': 88, 'learning_rate': 0.011931540527065477, 'min_child_samples': 241, 'min_gain_to_split': 0.015235767832390354}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 19:00:39,801] Trial 9 finished with value: 0.7389520040991415 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 569, 'max_depth': 21, 'n_estimators': 292, 'learning_rate': 0.346754351591591, 'min_child_samples': 285, 'min_gain_to_split': 0.009110061968757898}. Best is trial 2 with value: 0.764506874417849.\n",
      "[I 2024-10-21 19:00:49,003] Trial 10 finished with value: 0.7690515867037314 and parameters: {'boosting_type': 'goss', 'num_leaves': 242, 'max_depth': 62, 'n_estimators': 496, 'learning_rate': 0.048588032612719226, 'min_child_samples': 36, 'min_gain_to_split': 0.6768470100439602}. Best is trial 10 with value: 0.7690515867037314.\n",
      "[I 2024-10-21 19:00:58,173] Trial 11 finished with value: 0.7708233795938383 and parameters: {'boosting_type': 'goss', 'num_leaves': 218, 'max_depth': 64, 'n_estimators': 483, 'learning_rate': 0.046315167026764255, 'min_child_samples': 36, 'min_gain_to_split': 0.48105920763361354}. Best is trial 11 with value: 0.7708233795938383.\n",
      "[I 2024-10-21 19:01:10,377] Trial 12 finished with value: 0.760122685708911 and parameters: {'boosting_type': 'goss', 'num_leaves': 313, 'max_depth': 48, 'n_estimators': 492, 'learning_rate': 0.03784450181472439, 'min_child_samples': 7, 'min_gain_to_split': 0.14382380217820917}. Best is trial 11 with value: 0.7708233795938383.\n",
      "[I 2024-10-21 19:01:17,659] Trial 13 finished with value: 0.7434032020491815 and parameters: {'boosting_type': 'goss', 'num_leaves': 371, 'max_depth': 1, 'n_estimators': 497, 'learning_rate': 0.03609859997255306, 'min_child_samples': 27, 'min_gain_to_split': 0.8217795200494765}. Best is trial 11 with value: 0.7708233795938383.\n",
      "[I 2024-10-21 19:01:30,340] Trial 14 finished with value: 0.7688792476699966 and parameters: {'boosting_type': 'goss', 'num_leaves': 280, 'max_depth': 47, 'n_estimators': 418, 'learning_rate': 0.04256106825422551, 'min_child_samples': 91, 'min_gain_to_split': 0.10896132060092174}. Best is trial 11 with value: 0.7708233795938383.\n",
      "[I 2024-10-21 19:01:58,813] Trial 15 finished with value: 0.7704323232023648 and parameters: {'boosting_type': 'goss', 'num_leaves': 430, 'max_depth': 64, 'n_estimators': 436, 'learning_rate': 0.021568924852187286, 'min_child_samples': 80, 'min_gain_to_split': 0.055563873265946404}. Best is trial 11 with value: 0.7708233795938383.\n",
      "[I 2024-10-21 19:02:33,969] Trial 16 finished with value: 0.7708634895188538 and parameters: {'boosting_type': 'goss', 'num_leaves': 445, 'max_depth': 51, 'n_estimators': 420, 'learning_rate': 0.019821410774503927, 'min_child_samples': 121, 'min_gain_to_split': 0.06839542221931191}. Best is trial 16 with value: 0.7708634895188538.\n",
      "[I 2024-10-21 19:02:55,325] Trial 17 finished with value: 0.7706384031098684 and parameters: {'boosting_type': 'goss', 'num_leaves': 468, 'max_depth': 51, 'n_estimators': 366, 'learning_rate': 0.020724888322168702, 'min_child_samples': 119, 'min_gain_to_split': 0.2720938460443254}. Best is trial 16 with value: 0.7708634895188538.\n",
      "[I 2024-10-21 19:03:15,309] Trial 18 finished with value: 0.7730716323167628 and parameters: {'boosting_type': 'goss', 'num_leaves': 58, 'max_depth': 37, 'n_estimators': 446, 'learning_rate': 0.02022926203174373, 'min_child_samples': 167, 'min_gain_to_split': 0.0010123889304057472}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:03:31,703] Trial 19 finished with value: 0.769508726894708 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 24, 'max_depth': 39, 'n_estimators': 426, 'learning_rate': 0.019800629516993275, 'min_child_samples': 190, 'min_gain_to_split': 0.00014001868811241316}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:03:40,421] Trial 20 finished with value: 0.7689147499582895 and parameters: {'boosting_type': 'goss', 'num_leaves': 96, 'max_depth': 41, 'n_estimators': 318, 'learning_rate': 0.06872505315599817, 'min_child_samples': 168, 'min_gain_to_split': 0.0011493999986444982}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:03:59,959] Trial 21 finished with value: 0.771578355409533 and parameters: {'boosting_type': 'goss', 'num_leaves': 158, 'max_depth': 55, 'n_estimators': 452, 'learning_rate': 0.024662312554935718, 'min_child_samples': 118, 'min_gain_to_split': 0.036862307363449906}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:04:28,493] Trial 22 finished with value: 0.7725174968993372 and parameters: {'boosting_type': 'goss', 'num_leaves': 135, 'max_depth': 54, 'n_estimators': 382, 'learning_rate': 0.01603677502626911, 'min_child_samples': 132, 'min_gain_to_split': 0.028999319089827252}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:05:01,684] Trial 23 finished with value: 0.7729624302080734 and parameters: {'boosting_type': 'goss', 'num_leaves': 157, 'max_depth': 56, 'n_estimators': 386, 'learning_rate': 0.01518869499195478, 'min_child_samples': 221, 'min_gain_to_split': 0.02865998929239256}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:05:14,102] Trial 24 finished with value: 0.761962676095949 and parameters: {'boosting_type': 'goss', 'num_leaves': 20, 'max_depth': 43, 'n_estimators': 372, 'learning_rate': 0.013207386914139599, 'min_child_samples': 217, 'min_gain_to_split': 0.0012451726826436787}. Best is trial 18 with value: 0.7730716323167628.\n",
      "[I 2024-10-21 19:06:03,547] Trial 25 finished with value: 0.773164092599787 and parameters: {'boosting_type': 'goss', 'num_leaves': 151, 'max_depth': 34, 'n_estimators': 391, 'learning_rate': 0.014519458178866901, 'min_child_samples': 318, 'min_gain_to_split': 0.02369751870489948}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:06:10,796] Trial 26 finished with value: 0.7348996407234407 and parameters: {'boosting_type': 'goss', 'num_leaves': 233, 'max_depth': 2, 'n_estimators': 341, 'learning_rate': 0.010115810063888078, 'min_child_samples': 479, 'min_gain_to_split': 0.00045276722670528613}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:06:48,116] Trial 27 finished with value: 0.7716246107141097 and parameters: {'boosting_type': 'goss', 'num_leaves': 357, 'max_depth': 32, 'n_estimators': 457, 'learning_rate': 0.02968770841967944, 'min_child_samples': 327, 'min_gain_to_split': 0.01780051038646617}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:07:25,347] Trial 28 finished with value: 0.7717484968689571 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 173, 'max_depth': 11, 'n_estimators': 400, 'learning_rate': 0.014951243914299212, 'min_child_samples': 322, 'min_gain_to_split': 0.00629205458516507}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:10:31,837] Trial 29 finished with value: 0.7631341956916885 and parameters: {'boosting_type': 'dart', 'num_leaves': 977, 'max_depth': 33, 'n_estimators': 279, 'learning_rate': 0.057442961289118924, 'min_child_samples': 214, 'min_gain_to_split': 0.0014292810660546111}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:10:38,919] Trial 30 finished with value: 0.7681380723973018 and parameters: {'boosting_type': 'goss', 'num_leaves': 99, 'max_depth': 34, 'n_estimators': 349, 'learning_rate': 0.08541211436111643, 'min_child_samples': 287, 'min_gain_to_split': 0.00010772849218597468}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:11:06,975] Trial 31 finished with value: 0.7729885215101956 and parameters: {'boosting_type': 'goss', 'num_leaves': 118, 'max_depth': 57, 'n_estimators': 401, 'learning_rate': 0.015130116872699778, 'min_child_samples': 162, 'min_gain_to_split': 0.02196741245871082}. Best is trial 25 with value: 0.773164092599787.\n",
      "[I 2024-10-21 19:11:27,353] Trial 32 finished with value: 0.7742621248632311 and parameters: {'boosting_type': 'goss', 'num_leaves': 73, 'max_depth': 38, 'n_estimators': 461, 'learning_rate': 0.02822513797841152, 'min_child_samples': 197, 'min_gain_to_split': 0.01816164219917891}. Best is trial 32 with value: 0.7742621248632311.\n",
      "[I 2024-10-21 19:11:46,422] Trial 33 finished with value: 0.7730626630821712 and parameters: {'boosting_type': 'goss', 'num_leaves': 56, 'max_depth': 37, 'n_estimators': 464, 'learning_rate': 0.029549256733628612, 'min_child_samples': 169, 'min_gain_to_split': 0.013394875397888027}. Best is trial 32 with value: 0.7742621248632311.\n",
      "[I 2024-10-21 19:12:06,779] Trial 34 finished with value: 0.7743318433276246 and parameters: {'boosting_type': 'goss', 'num_leaves': 64, 'max_depth': 38, 'n_estimators': 446, 'learning_rate': 0.028614050667661064, 'min_child_samples': 184, 'min_gain_to_split': 0.010537902636855629}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:12:14,078] Trial 35 finished with value: 0.7638713280986666 and parameters: {'boosting_type': 'goss', 'num_leaves': 197, 'max_depth': 43, 'n_estimators': 455, 'learning_rate': 0.12292273668045361, 'min_child_samples': 363, 'min_gain_to_split': 0.002313964822426995}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:12:38,532] Trial 36 finished with value: 0.7403875597320129 and parameters: {'boosting_type': 'dart', 'num_leaves': 21, 'max_depth': 29, 'n_estimators': 235, 'learning_rate': 0.024700674788399834, 'min_child_samples': 190, 'min_gain_to_split': 0.008447704513815161}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:12:41,208] Trial 37 finished with value: 0.7211000539199741 and parameters: {'boosting_type': 'goss', 'num_leaves': 286, 'max_depth': 26, 'n_estimators': 472, 'learning_rate': 0.8368862737038494, 'min_child_samples': 245, 'min_gain_to_split': 0.004064625449578519}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:12:58,980] Trial 38 finished with value: 0.7735291024234754 and parameters: {'boosting_type': 'goss', 'num_leaves': 83, 'max_depth': 38, 'n_estimators': 436, 'learning_rate': 0.031579263473185355, 'min_child_samples': 424, 'min_gain_to_split': 0.0007190354576772128}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:13:34,397] Trial 39 finished with value: 0.7640808134075833 and parameters: {'boosting_type': 'dart', 'num_leaves': 104, 'max_depth': 46, 'n_estimators': 187, 'learning_rate': 0.06400112679262718, 'min_child_samples': 435, 'min_gain_to_split': 0.05046641477265458}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:14:26,806] Trial 40 finished with value: 0.7702210373363794 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 361, 'max_depth': 30, 'n_estimators': 431, 'learning_rate': 0.030606345934762736, 'min_child_samples': 417, 'min_gain_to_split': 0.0004950394705623782}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:14:45,087] Trial 41 finished with value: 0.773709577514773 and parameters: {'boosting_type': 'goss', 'num_leaves': 70, 'max_depth': 36, 'n_estimators': 407, 'learning_rate': 0.03237559638642215, 'min_child_samples': 448, 'min_gain_to_split': 0.0008093224682092678}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:15:08,490] Trial 42 finished with value: 0.7723611336157447 and parameters: {'boosting_type': 'goss', 'num_leaves': 728, 'max_depth': 35, 'n_estimators': 405, 'learning_rate': 0.033634367672087113, 'min_child_samples': 494, 'min_gain_to_split': 0.0002186793153559933}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:15:19,324] Trial 43 finished with value: 0.7732365230833681 and parameters: {'boosting_type': 'goss', 'num_leaves': 66, 'max_depth': 39, 'n_estimators': 315, 'learning_rate': 0.053498283025670924, 'min_child_samples': 434, 'min_gain_to_split': 0.0025483228666178474}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:15:32,281] Trial 44 finished with value: 0.772820521707161 and parameters: {'boosting_type': 'goss', 'num_leaves': 74, 'max_depth': 40, 'n_estimators': 309, 'learning_rate': 0.05411560821030471, 'min_child_samples': 456, 'min_gain_to_split': 0.0006749745792777121}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:15:40,010] Trial 45 finished with value: 0.7681009317139125 and parameters: {'boosting_type': 'goss', 'num_leaves': 214, 'max_depth': 44, 'n_estimators': 358, 'learning_rate': 0.0833034964834481, 'min_child_samples': 406, 'min_gain_to_split': 0.002213190591419428}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:15:52,502] Trial 46 finished with value: 0.7731978222899717 and parameters: {'boosting_type': 'goss', 'num_leaves': 62, 'max_depth': 24, 'n_estimators': 478, 'learning_rate': 0.042445636595882595, 'min_child_samples': 394, 'min_gain_to_split': 0.004057200721955162}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:16:27,668] Trial 47 finished with value: 0.7668305492331492 and parameters: {'boosting_type': 'dart', 'num_leaves': 121, 'max_depth': 38, 'n_estimators': 185, 'learning_rate': 0.11041759471738162, 'min_child_samples': 450, 'min_gain_to_split': 0.0002438180311674536}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:16:32,615] Trial 48 finished with value: 0.7636113600903159 and parameters: {'boosting_type': 'goss', 'num_leaves': 260, 'max_depth': 40, 'n_estimators': 262, 'learning_rate': 0.14918235677747216, 'min_child_samples': 355, 'min_gain_to_split': 0.001796211060278159}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:17:15,612] Trial 49 finished with value: 0.7717563477451207 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 196, 'max_depth': 27, 'n_estimators': 329, 'learning_rate': 0.025952212300617054, 'min_child_samples': 476, 'min_gain_to_split': 0.000699936965088622}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:17:33,848] Trial 50 finished with value: 0.7722322036643875 and parameters: {'boosting_type': 'goss', 'num_leaves': 582, 'max_depth': 49, 'n_estimators': 413, 'learning_rate': 0.04384826346159517, 'min_child_samples': 391, 'min_gain_to_split': 0.0035727895159246336}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:17:47,240] Trial 51 finished with value: 0.7738045429206757 and parameters: {'boosting_type': 'goss', 'num_leaves': 58, 'max_depth': 21, 'n_estimators': 475, 'learning_rate': 0.038522356695941715, 'min_child_samples': 441, 'min_gain_to_split': 0.006987838364932312}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:18:02,058] Trial 52 finished with value: 0.7742285964775635 and parameters: {'boosting_type': 'goss', 'num_leaves': 62, 'max_depth': 14, 'n_estimators': 483, 'learning_rate': 0.036005335843608766, 'min_child_samples': 442, 'min_gain_to_split': 0.005837549089347575}. Best is trial 34 with value: 0.7743318433276246.\n",
      "[I 2024-10-21 19:18:18,043] Trial 53 finished with value: 0.7749731268255419 and parameters: {'boosting_type': 'goss', 'num_leaves': 43, 'max_depth': 12, 'n_estimators': 475, 'learning_rate': 0.034884880574996446, 'min_child_samples': 459, 'min_gain_to_split': 0.007717035822662368}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:18:30,744] Trial 54 finished with value: 0.7727337986028718 and parameters: {'boosting_type': 'goss', 'num_leaves': 41, 'max_depth': 15, 'n_estimators': 486, 'learning_rate': 0.038587696814813575, 'min_child_samples': 461, 'min_gain_to_split': 0.006165470077680552}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:18:33,295] Trial 55 finished with value: 0.7544095349047577 and parameters: {'boosting_type': 'goss', 'num_leaves': 119, 'max_depth': 7, 'n_estimators': 499, 'learning_rate': 0.5329166390009581, 'min_child_samples': 498, 'min_gain_to_split': 0.009934011046162027}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:18:43,929] Trial 56 finished with value: 0.7665250584449921 and parameters: {'boosting_type': 'goss', 'num_leaves': 183, 'max_depth': 20, 'n_estimators': 474, 'learning_rate': 0.07345525314297116, 'min_child_samples': 260, 'min_gain_to_split': 0.013028770372011842}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:19:18,940] Trial 57 finished with value: 0.7730037703273597 and parameters: {'boosting_type': 'goss', 'num_leaves': 804, 'max_depth': 13, 'n_estimators': 443, 'learning_rate': 0.018018233770879608, 'min_child_samples': 345, 'min_gain_to_split': 0.006065101046717378}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:19:39,635] Trial 58 finished with value: 0.7732368194483515 and parameters: {'boosting_type': 'goss', 'num_leaves': 139, 'max_depth': 10, 'n_estimators': 467, 'learning_rate': 0.025443269256279467, 'min_child_samples': 472, 'min_gain_to_split': 0.008624908913990498}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:19:55,993] Trial 59 finished with value: 0.7696837779476302 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 663, 'max_depth': 18, 'n_estimators': 134, 'learning_rate': 0.036889164318837306, 'min_child_samples': 384, 'min_gain_to_split': 0.09796983527358065}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:20:21,956] Trial 60 finished with value: 0.7741988481433821 and parameters: {'boosting_type': 'goss', 'num_leaves': 45, 'max_depth': 8, 'n_estimators': 485, 'learning_rate': 0.02289465314371275, 'min_child_samples': 294, 'min_gain_to_split': 0.040307706175719736}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:20:37,924] Trial 61 finished with value: 0.772212682718029 and parameters: {'boosting_type': 'goss', 'num_leaves': 86, 'max_depth': 6, 'n_estimators': 488, 'learning_rate': 0.021897700358002647, 'min_child_samples': 442, 'min_gain_to_split': 0.04012500146271983}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:20:50,069] Trial 62 finished with value: 0.7740808333702811 and parameters: {'boosting_type': 'goss', 'num_leaves': 41, 'max_depth': 5, 'n_estimators': 443, 'learning_rate': 0.04471648047981411, 'min_child_samples': 282, 'min_gain_to_split': 0.018016204778802797}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:21:01,643] Trial 63 finished with value: 0.7738436798738589 and parameters: {'boosting_type': 'goss', 'num_leaves': 26, 'max_depth': -1, 'n_estimators': 457, 'learning_rate': 0.04738240595720424, 'min_child_samples': 298, 'min_gain_to_split': 0.018382425065257692}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:21:12,802] Trial 64 finished with value: 0.7749211175668538 and parameters: {'boosting_type': 'goss', 'num_leaves': 22, 'max_depth': -1, 'n_estimators': 448, 'learning_rate': 0.045413215856018666, 'min_child_samples': 293, 'min_gain_to_split': 0.02006667436830226}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:21:23,029] Trial 65 finished with value: 0.7683709258055688 and parameters: {'boosting_type': 'goss', 'num_leaves': 520, 'max_depth': 4, 'n_estimators': 425, 'learning_rate': 0.028057858699624343, 'min_child_samples': 231, 'min_gain_to_split': 0.07063060765460381}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:21:42,964] Trial 66 finished with value: 0.773447663562758 and parameters: {'boosting_type': 'goss', 'num_leaves': 142, 'max_depth': 7, 'n_estimators': 499, 'learning_rate': 0.022767614100928923, 'min_child_samples': 265, 'min_gain_to_split': 0.012124009821642424}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:22:12,234] Trial 67 finished with value: 0.773330017847938 and parameters: {'boosting_type': 'goss', 'num_leaves': 103, 'max_depth': -1, 'n_estimators': 448, 'learning_rate': 0.017132615630324668, 'min_child_samples': 203, 'min_gain_to_split': 0.02842458608749606}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:22:17,201] Trial 68 finished with value: 0.7405901895037665 and parameters: {'boosting_type': 'dart', 'num_leaves': 21, 'max_depth': 9, 'n_estimators': 67, 'learning_rate': 0.05044031272283417, 'min_child_samples': 280, 'min_gain_to_split': 0.1914173496742475}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:22:27,108] Trial 69 finished with value: 0.753029340809962 and parameters: {'boosting_type': 'goss', 'num_leaves': 170, 'max_depth': 3, 'n_estimators': 439, 'learning_rate': 0.01284460092854658, 'min_child_samples': 340, 'min_gain_to_split': 0.01671872339362909}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:22:34,970] Trial 70 finished with value: 0.7724799983412508 and parameters: {'boosting_type': 'goss', 'num_leaves': 41, 'max_depth': 13, 'n_estimators': 465, 'learning_rate': 0.06540100448625993, 'min_child_samples': 304, 'min_gain_to_split': 0.04575334654535838}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:22:53,892] Trial 71 finished with value: 0.7728106801529957 and parameters: {'boosting_type': 'goss', 'num_leaves': 41, 'max_depth': -1, 'n_estimators': 484, 'learning_rate': 0.048264700407333654, 'min_child_samples': 147, 'min_gain_to_split': 0.01979244750870133}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:23:08,233] Trial 72 finished with value: 0.7442722839752719 and parameters: {'boosting_type': 'goss', 'num_leaves': 89, 'max_depth': 1, 'n_estimators': 456, 'learning_rate': 0.04196711579674312, 'min_child_samples': 298, 'min_gain_to_split': 0.030284340477088605}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:23:22,838] Trial 73 finished with value: 0.7741019032430622 and parameters: {'boosting_type': 'goss', 'num_leaves': 47, 'max_depth': 5, 'n_estimators': 420, 'learning_rate': 0.06121432047043211, 'min_child_samples': 240, 'min_gain_to_split': 0.015554248590318396}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:23:32,906] Trial 74 finished with value: 0.7708226302936916 and parameters: {'boosting_type': 'goss', 'num_leaves': 123, 'max_depth': 6, 'n_estimators': 420, 'learning_rate': 0.062269904424839706, 'min_child_samples': 233, 'min_gain_to_split': 0.011067602155838964}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:23:42,298] Trial 75 finished with value: 0.7712558767568565 and parameters: {'boosting_type': 'goss', 'num_leaves': 52, 'max_depth': 12, 'n_estimators': 432, 'learning_rate': 0.07471639730011777, 'min_child_samples': 190, 'min_gain_to_split': 0.015574200846323027}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:23:58,201] Trial 76 finished with value: 0.7713210826449935 and parameters: {'boosting_type': 'goss', 'num_leaves': 98, 'max_depth': 4, 'n_estimators': 441, 'learning_rate': 0.03503503258517893, 'min_child_samples': 255, 'min_gain_to_split': 0.06470885993282359}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:24:28,419] Trial 77 finished with value: 0.7678012452059959 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 155, 'max_depth': 9, 'n_estimators': 217, 'learning_rate': 0.01866937054280121, 'min_child_samples': 274, 'min_gain_to_split': 0.024933667438490445}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:24:49,696] Trial 78 finished with value: 0.7731467077180257 and parameters: {'boosting_type': 'goss', 'num_leaves': 78, 'max_depth': 16, 'n_estimators': 394, 'learning_rate': 0.03409352167419525, 'min_child_samples': 204, 'min_gain_to_split': 0.007627709730739884}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:25:02,917] Trial 79 finished with value: 0.7736644405686242 and parameters: {'boosting_type': 'goss', 'num_leaves': 45, 'max_depth': 4, 'n_estimators': 465, 'learning_rate': 0.05594156643652526, 'min_child_samples': 144, 'min_gain_to_split': 0.014301911159220155}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:25:25,167] Trial 80 finished with value: 0.7728146838761674 and parameters: {'boosting_type': 'goss', 'num_leaves': 321, 'max_depth': 8, 'n_estimators': 484, 'learning_rate': 0.027846369947832038, 'min_child_samples': 180, 'min_gain_to_split': 0.0030479507539536263}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:25:32,394] Trial 81 finished with value: 0.7451709996038048 and parameters: {'boosting_type': 'goss', 'num_leaves': 21, 'max_depth': 1, 'n_estimators': 458, 'learning_rate': 0.045459628277088604, 'min_child_samples': 299, 'min_gain_to_split': 0.01920020836916458}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:25:45,618] Trial 82 finished with value: 0.7709324642748929 and parameters: {'boosting_type': 'goss', 'num_leaves': 113, 'max_depth': -1, 'n_estimators': 449, 'learning_rate': 0.04021339234497239, 'min_child_samples': 288, 'min_gain_to_split': 0.010037975929722352}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:25:52,960] Trial 83 finished with value: 0.7677221996323138 and parameters: {'boosting_type': 'goss', 'num_leaves': 40, 'max_depth': 2, 'n_estimators': 415, 'learning_rate': 0.1004967868789265, 'min_child_samples': 245, 'min_gain_to_split': 0.005038001447216951}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:26:03,803] Trial 84 finished with value: 0.7719848731062717 and parameters: {'boosting_type': 'goss', 'num_leaves': 75, 'max_depth': 6, 'n_estimators': 473, 'learning_rate': 0.049420305222694735, 'min_child_samples': 308, 'min_gain_to_split': 0.0051207141713529945}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:27:22,379] Trial 85 finished with value: 0.7690570051503145 and parameters: {'boosting_type': 'dart', 'num_leaves': 127, 'max_depth': 5, 'n_estimators': 492, 'learning_rate': 0.0587974069675165, 'min_child_samples': 92, 'min_gain_to_split': 0.021166767759268235}. Best is trial 53 with value: 0.7749731268255419.\n",
      "[I 2024-10-21 19:27:43,348] Trial 86 finished with value: 0.7750874118732859 and parameters: {'boosting_type': 'goss', 'num_leaves': 67, 'max_depth': 11, 'n_estimators': 426, 'learning_rate': 0.023663556125518563, 'min_child_samples': 270, 'min_gain_to_split': 0.026685985757266675}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:28:07,414] Trial 87 finished with value: 0.7732634755214798 and parameters: {'boosting_type': 'goss', 'num_leaves': 221, 'max_depth': 11, 'n_estimators': 433, 'learning_rate': 0.0232164563361347, 'min_child_samples': 223, 'min_gain_to_split': 0.03570797203270969}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:28:23,741] Trial 88 finished with value: 0.7738438811783761 and parameters: {'boosting_type': 'goss', 'num_leaves': 96, 'max_depth': 14, 'n_estimators': 423, 'learning_rate': 0.0290258768770294, 'min_child_samples': 238, 'min_gain_to_split': 0.035407921327978494}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:28:42,840] Trial 89 finished with value: 0.7733475257491264 and parameters: {'boosting_type': 'goss', 'num_leaves': 70, 'max_depth': 17, 'n_estimators': 378, 'learning_rate': 0.020641535753129978, 'min_child_samples': 266, 'min_gain_to_split': 0.09346310601216296}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:29:02,400] Trial 90 finished with value: 0.7738694412602449 and parameters: {'boosting_type': 'goss', 'num_leaves': 151, 'max_depth': 10, 'n_estimators': 411, 'learning_rate': 0.02662656758249264, 'min_child_samples': 330, 'min_gain_to_split': 0.053250855718951336}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:29:20,796] Trial 91 finished with value: 0.7735226327199702 and parameters: {'boosting_type': 'goss', 'num_leaves': 59, 'max_depth': 10, 'n_estimators': 408, 'learning_rate': 0.025892004679778154, 'min_child_samples': 325, 'min_gain_to_split': 0.023521314706209853}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:29:39,903] Trial 92 finished with value: 0.7729384246444193 and parameters: {'boosting_type': 'goss', 'num_leaves': 405, 'max_depth': 8, 'n_estimators': 449, 'learning_rate': 0.031952878013376596, 'min_child_samples': 253, 'min_gain_to_split': 0.05358378689268444}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:29:56,476] Trial 93 finished with value: 0.772540154841086 and parameters: {'boosting_type': 'goss', 'num_leaves': 144, 'max_depth': 12, 'n_estimators': 397, 'learning_rate': 0.03644196683442847, 'min_child_samples': 333, 'min_gain_to_split': 0.042907270335382205}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:30:15,223] Trial 94 finished with value: 0.7733908341792457 and parameters: {'boosting_type': 'goss', 'num_leaves': 89, 'max_depth': 60, 'n_estimators': 479, 'learning_rate': 0.028225029810879217, 'min_child_samples': 367, 'min_gain_to_split': 0.07296420535768765}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:30:41,801] Trial 95 finished with value: 0.7741917353837809 and parameters: {'boosting_type': 'goss', 'num_leaves': 171, 'max_depth': 15, 'n_estimators': 427, 'learning_rate': 0.024059952542036776, 'min_child_samples': 314, 'min_gain_to_split': 0.028557330600727307}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:31:07,658] Trial 96 finished with value: 0.7720583995811122 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 187, 'max_depth': 15, 'n_estimators': 440, 'learning_rate': 0.023862847634554048, 'min_child_samples': 312, 'min_gain_to_split': 0.012696165770373464}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:31:15,928] Trial 97 finished with value: 0.7477092035245311 and parameters: {'boosting_type': 'goss', 'num_leaves': 38, 'max_depth': 2, 'n_estimators': 459, 'learning_rate': 0.016715626994569032, 'min_child_samples': 287, 'min_gain_to_split': 0.02861725893305459}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:31:42,315] Trial 98 finished with value: 0.7743898581710702 and parameters: {'boosting_type': 'goss', 'num_leaves': 106, 'max_depth': 20, 'n_estimators': 429, 'learning_rate': 0.019993501342484274, 'min_child_samples': 209, 'min_gain_to_split': 0.008467706800444886}. Best is trial 86 with value: 0.7750874118732859.\n",
      "[I 2024-10-21 19:33:24,154] Trial 99 finished with value: 0.7596823264861446 and parameters: {'boosting_type': 'dart', 'num_leaves': 112, 'max_depth': 18, 'n_estimators': 431, 'learning_rate': 0.02233894859796255, 'min_child_samples': 206, 'min_gain_to_split': 0.009531510965949121}. Best is trial 86 with value: 0.7750874118732859.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.7750874118732859\n",
      "  Params: \n",
      "    boosting_type: goss\n",
      "    num_leaves: 67\n",
      "    max_depth: 11\n",
      "    n_estimators: 426\n",
      "    learning_rate: 0.023663556125518563\n",
      "    min_child_samples: 270\n",
      "    min_gain_to_split: 0.026685985757266675\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 1000), \n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 64),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 500),  \n",
    "        'min_gain_to_split': trial.suggest_loguniform('min_gain_to_split', 0.0001, 1.0)   \n",
    "    }\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_test_scaled, label=y_test, reference=train_data)\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        param,\n",
    "        train_data,\n",
    "        valid_sets=[valid_data],  \n",
    "        num_boost_round=100,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=10, verbose=False)]\n",
    "    )\n",
    "\n",
    "    y_pred = gbm.predict(X_test_scaled, num_iteration=gbm.best_iteration)\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LGBM Pipeline Optuna Optimized**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the hyperparameters identified by Optuna to tune my LGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "columns_to_scale = ['ANNUITY_TO_CREDIT_RATIO', \n",
    "                    'EXT_SOURCE_3',\n",
    "                    'EXT_SOURCE_2',\n",
    "                    'EXT_SOURCE_1',\n",
    "                    'EXT_SOURCE_MEAN',\n",
    "                    'ANNUAL_PAYMENT_TO_CREDIT_RATIO',\n",
    "                    'AGE',\n",
    "                    'YEARS_ID_PUBLISH',\n",
    "                    'AMT_ANNUITY',\n",
    "                    'AMT_GOODS_PRICE',\n",
    "                    'ANNUITY_TO_INCOME_RATIO',\n",
    "                    'YEARS_REGISTRATION',\n",
    "                    'YEARS_LAST_PHONE_CHANGE',\n",
    "                    'YEARS_EMPLOYED_AGE_PRODUCT',\n",
    "                    'INCOME_TO_AGE_RATIO',\n",
    "                    'REGION_POPULATION_RELATIVE',\n",
    "                    'AVG_MAX_DPD',\n",
    "                    'TOTAL_DEBIT',\n",
    "                    'TOTAL_CREDIT_AMT', \n",
    "                    'DEBT_CREDIT_RATIO',\n",
    "                    'AVG_ANNUITY_AMOUNT',\n",
    "                    'AVG_DAYS_DECISION',\n",
    "                    'RANGE_DAYS_FIRST_DUE',\n",
    "                    'RANGE_DAYS_LAST_DUE',\n",
    "                    'SUM_AMT_INSTALMENT',\n",
    "                    'AVG_AMT_INSTALMENT',\n",
    "                    'SUM_AMT_PAYMENT',\n",
    "                    'AVG_AMT_PAYMENT',\n",
    "                    'MAX_AMT_PAYMENT',\n",
    "                    'MIN_AMT_PAYMENT',\n",
    "                    'SUM_AMT_PAYMENT/SUM_AMT_INSTALMENT',\n",
    "                    'MEAN_AMT_PAYMENT-MEAN_AMT_INSTALMENT'\n",
    "                    ]\n",
    "\n",
    "columns_to_encode = ['ORGANIZATION_TYPE']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scaler', StandardScaler(), columns_to_scale),\n",
    "        ('encoder', WoEEncoder(fill_value=.000001), columns_to_encode)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "lgbm_model = lgb.LGBMClassifier(boosting_type='goss', \n",
    "                           num_leaves=67, \n",
    "                           max_depth=11, \n",
    "                           learning_rate=0.023663556125518563, \n",
    "                           n_estimators=426,\n",
    "                            min_child_samples=270,\n",
    "                            min_gain_to_split=0.026685985757266675, \n",
    "                           verbose=-1)\n",
    "\n",
    "lgbm_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('lgbm', lgbm_model)\n",
    "])\n",
    "\n",
    "pipelines = {\n",
    "    \"lgbm\": lgbm_pipeline,\n",
    "}\n",
    "\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_prob = pipeline.predict_proba(X_test)[:, 1]\n",
    "    auc_score = roc_auc_score(y_test, y_prob)\n",
    "    print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 64),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**param, random_state=0)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGB Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-29 17:22:06,064] A new study created in memory with name: no-name-def73e19-20c9-48e2-bd12-2b17cd4e7d68\n",
      "[I 2024-10-29 17:25:10,842] Trial 0 finished with value: 0.768472047774617 and parameters: {'n_estimators': 430, 'learning_rate': 0.012685207556507958, 'max_depth': 14, 'subsample': 0.5920557351301199, 'colsample_bytree': 0.9202741690730589}. Best is trial 0 with value: 0.768472047774617.\n",
      "[I 2024-10-29 17:26:51,722] Trial 1 finished with value: 0.7466922047168746 and parameters: {'n_estimators': 64, 'learning_rate': 0.03438816708945239, 'max_depth': 56, 'subsample': 0.5449450580496265, 'colsample_bytree': 0.8521524054833501}. Best is trial 0 with value: 0.768472047774617.\n",
      "[I 2024-10-29 17:29:38,095] Trial 2 finished with value: 0.7600512114217857 and parameters: {'n_estimators': 159, 'learning_rate': 0.023047606646611422, 'max_depth': 18, 'subsample': 0.7844473036154253, 'colsample_bytree': 0.9032323448834018}. Best is trial 0 with value: 0.768472047774617.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 64),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = XGBClassifier(**param, use_label_encoder=False, eval_metric='logloss', random_state=0)\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train, verbose=False)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pickle File for Streamlit Deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will later use Streamlilt for deployment (See notebook 13.0). Here, I create a Pickle file for the Streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lgbm_pipeline.pkl', 'wb') as file:\n",
    "    pickle.dump(lgbm_pipeline, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * **LightGBM** — The best performing model was LightGBM. \n",
    "> * **Optuna** — After hyperparameter tuning using Optuna, ROC-AUC score inceased by 3%, from 74% to 77%. \n",
    "> * **Pickle File** — I created a Pickle file for Streamlit deployment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
