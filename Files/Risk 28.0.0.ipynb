{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.imputation import ArbitraryNumberImputer\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_rows = 300000\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('use_inf_as_na', True)\n",
    "\n",
    "data = pd.read_csv(\n",
    "    r\"C:\\Users\\Dell\\Documents\\AI\\Risk\\Data\\Data\\Data\\data.csv\",\n",
    "    index_col=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce Memory Usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 296.02 MB\n",
      "Memory usage after optimization is: 104.37 MB\n",
      "Decreased by 64.7%\n"
     ]
    }
   ],
   "source": [
    "data = functions.reduce_memory_usage(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 101\n",
    "target = 'TARGET'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani = ArbitraryNumberImputer(arbitrary_number=-99999)\n",
    "ani.fit(data)\n",
    "data = ani.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = CategoricalImputer(imputation_method='missing', fill_value='UNKNOWN')\n",
    "ci.fit(data)\n",
    "data = ci.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **WoE Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "woe = WoEEncoder(fill_value=0.0001)\n",
    "woe.fit(data, data[target])\n",
    "data = woe.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "X, y = shuffle(X, y, random_state=random_state)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "model = lgb.LGBMClassifier(boosting_type='gbdt', \n",
    "                           num_leaves=31, \n",
    "                           max_depth=-1, \n",
    "                           learning_rate=0.1, \n",
    "                           n_estimators=100,\n",
    "                           verbose=-1)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_prob = model.predict_proba(X_test)[:, 1]  \n",
    "\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "print(f\"AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Recursive Feature Elimination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svc = SVC(kernel=\"linear\", probability=True)  \n",
    "\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=5, scoring='roc_auc')\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "print(f\"Selected features: {rfecv.support_}\")\n",
    "print(f\"Feature ranking: {rfecv.ranking_}\")\n",
    "\n",
    "\n",
    "y_prob = rfecv.predict_proba(X_test)[:, 1] \n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(f\"Test set AUC: {auc:.4f}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"RFECV: Recursive Feature Elimination with Cross-Validation\")\n",
    "plt.xlabel(\"Number of Features Selected\")\n",
    "plt.ylabel(\"Cross Validation Score (AUC)\")\n",
    "plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'], marker='o')\n",
    "plt.axvline(rfecv.n_features_, linestyle='--', color='red')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assume you have X_train, X_test as numpy arrays and y_train as the target (could be a numpy array or Series)\n",
    "# If you have feature names separately, store them in a list:\n",
    "feature_names = [...]  # List of column names corresponding to X_train\n",
    "\n",
    "# Standardize the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to X_train and X_test (they are numpy arrays)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize LightGBM Classifier\n",
    "lgb_clf = LGBMClassifier()\n",
    "\n",
    "# Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "rfecv = RFECV(estimator=lgb_clf, step=1, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Fit RFECV with the scaled training data\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the optimal number of features\n",
    "print(\"Optimal number of features (LightGBM): \", rfecv.n_features_)\n",
    "\n",
    "# Plot the cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (roc_auc)\")\n",
    "\n",
    "# Use either grid_scores_ or cv_results_['mean_test_score'] based on the sklearn version\n",
    "if hasattr(rfecv, 'grid_scores_'):\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "else:\n",
    "    plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# If feature_names is defined (as a list of column names), use it to get the selected features\n",
    "if feature_names:\n",
    "    selected_features_lgb = np.array(feature_names)[rfecv.support_]\n",
    "    print(\"Selected features: \", selected_features_lgb)\n",
    "else:\n",
    "    print(\"Selected feature indices: \", np.where(rfecv.support_)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have X_train, X_test as numpy arrays and y_train as the target\n",
    "# If you have feature names separately, store them in a list:\n",
    "feature_names = [...]  # List of column names corresponding to X_train\n",
    "\n",
    "\n",
    "lgb_clf = LGBMClassifier(verbosity=-1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rfecv = RFECV(estimator=lgb_clf, step=1, cv=5, scoring='roc_auc')\n",
    "\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Optimal number of features (LightGBM): \", rfecv.n_features_)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross-validation score (roc_auc)\")\n",
    "\n",
    "if hasattr(rfecv, 'grid_scores_'):\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "else:\n",
    "    plt.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), rfecv.cv_results_['mean_test_score'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "if feature_names:\n",
    "    selected_features_lgb = np.array(feature_names)[rfecv.support_]\n",
    "    print(\"Selected features: \", selected_features_lgb)\n",
    "else:\n",
    "    print(\"Selected feature indices: \", np.where(rfecv.support_)[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
